{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score, AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix(task='multiclass', num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([0, 1, 1, 1, 0, 2, 0, 2, 1, 1]).to(device)\n",
    "pred_probs = torch.tensor(\n",
    "    [\n",
    "        [0.6, 0.3, 0.1],\n",
    "        [0.1, 0.8, 0.1],\n",
    "        [0.2, 0.7, 0.1],\n",
    "        [0.2, 0.6, 0.2],\n",
    "        [0.9, 0.05, 0.05],\n",
    "        [0.1, 0.3, 0.6],\n",
    "        [0.7, 0.1, 0.2],\n",
    "        [0.1, 0.1, 0.8],\n",
    "        [0.4, 0.6, 0.0],\n",
    "        [0.01, 0.9, 0.09],\n",
    "    ]\n",
    ").to(device)\n",
    "\n",
    "targets = torch.tensor([0, 0, 1, 2, 0, 1, 0, 2, 2, 1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 0],\n",
       "        [0, 2, 1],\n",
       "        [0, 2, 1]], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confmat(preds, targets)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_mean(a, b):\n",
    "    if a + b == 0: return 0\n",
    "    return 2 * a * b / (a + b)\n",
    "\n",
    "def manage_nan(tensor):\n",
    "    return tensor if not torch.isnan(tensor).item() else torch.tensor(0.0).to(device)\n",
    "\n",
    "def confmat_to_accuracy(confmat): # micro\n",
    "    num_classes = confmat.shape[0]\n",
    "\n",
    "    correct_preds = 0\n",
    "    for i in range(num_classes):\n",
    "        correct_preds += confmat[i, i]\n",
    "    all_preds = confmat.sum()\n",
    "\n",
    "    acc = manage_nan(correct_preds / all_preds)\n",
    "\n",
    "    return acc.item()\n",
    "\n",
    "def confmat_to_precision(confmat): # macro\n",
    "    num_classes = confmat.shape[0]\n",
    "\n",
    "    if num_classes == 2:\n",
    "        return manage_nan(confmat[1, 1] / confmat[:, 1].sum()).item()\n",
    "\n",
    "    prec = 0\n",
    "    for i in range(num_classes):\n",
    "        prec += manage_nan(confmat[i, i] / confmat[:, i].sum())\n",
    "    prec /= num_classes\n",
    "\n",
    "    return prec.item()\n",
    "\n",
    "def confmat_to_recall(confmat): # macro\n",
    "    num_classes = confmat.shape[0]\n",
    "\n",
    "    if num_classes == 2:\n",
    "        return manage_nan(confmat[1, 1] / confmat[1].sum()).item()\n",
    "\n",
    "    rec = 0\n",
    "    for i in range(num_classes):\n",
    "        rec += manage_nan(confmat[i, i] / confmat[i].sum())\n",
    "    rec /= num_classes\n",
    "\n",
    "    return rec.item()\n",
    "\n",
    "def confmat_to_f1score(confmat): # macro\n",
    "    num_classes = confmat.shape[0]\n",
    "\n",
    "    if num_classes == 2:\n",
    "        return harmonic_mean(confmat_to_precision(confmat), confmat_to_recall(confmat))\n",
    "\n",
    "    f1 = 0\n",
    "    for i in range(num_classes):\n",
    "        prec = manage_nan(confmat[i, i] / confmat[:, i].sum())\n",
    "        rec = manage_nan(confmat[i, i] / confmat[i].sum())\n",
    "\n",
    "        f1 += harmonic_mean(prec, rec)\n",
    "    f1 /= num_classes\n",
    "\n",
    "    return f1.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6000000238418579, 0.6000000238418579)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_to_accuracy(cm), Accuracy(task='multiclass', num_classes=3, average='micro').to(device)(preds, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6333333253860474, 0.6333333253860474)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_to_precision(cm), Precision(task='multiclass', num_classes=3, average='macro').to(device)(preds, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5833333730697632, 0.5833333134651184)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_to_recall(cm), Recall(task='multiclass', num_classes=3, average='macro').to(device)(preds, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5857143402099609, 0.5857143402099609)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_to_f1score(cm), F1Score(task='multiclass', num_classes=3, average='macro').to(device)(preds, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380952835083008"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUROC(task='multiclass', num_classes=3, average='macro').to(device)(pred_probs, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = torch.tensor([1, 1, 1, 2, 2, 2, 2, 2, 2]).to(device)\n",
    "targets = torch.tensor([0, 1, 2, 0, 0, 1, 1, 2, 2]).to(device)\n",
    "\n",
    "cm = confmat(preds, targets)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.222222238779068, 0.2222222238779068)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat_to_precision(cm), Precision(task='multiclass', num_classes=3, average='macro').to(device)(preds, targets).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0874],\n",
       "        [0.9560],\n",
       "        [0.7305],\n",
       "        [0.5089],\n",
       "        [0.4520],\n",
       "        [0.4855],\n",
       "        [0.5623],\n",
       "        [0.1986],\n",
       "        [0.3550],\n",
       "        [0.9742]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = torch.tensor([[8, 0], [8, 0]])\n",
    "\n",
    "confmat_to_precision(cm), confmat_to_recall(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_mean(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val code without using confmat\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# accuracy_metric = Accuracy(task='multiclass', num_classes=3, average='micro').to(device)\n",
    "# precision_metric = Precision(task='multiclass', num_classes=3, average='macro').to(device)\n",
    "# recall_metric = Recall(task='multiclass', num_classes=3, average='macro').to(device)\n",
    "# f1score_metric = F1Score(task='multiclass', num_classes=3, average='macro').to(device)\n",
    "# auroc_metric = AUROC(task='multiclass', num_classes=3).to(device)\n",
    "\n",
    "# if WANNA_TRAIN:=True:\n",
    "#     length = len(val_dataloader)\n",
    "#     loss = 0\n",
    "#     acc = 0\n",
    "#     prec = 0\n",
    "#     rec = 0\n",
    "#     f1 = 0\n",
    "#     auroc = 0\n",
    "\n",
    "#     model.eval()\n",
    "#     with torch.inference_mode():\n",
    "#         for X, y in tqdm(val_dataloader):\n",
    "#             X, y = X.to(device), y.to(device)\n",
    "#             logits = model(X)\n",
    "#             probs = logits.softmax(1)\n",
    "#             labels = probs.argmax(1)\n",
    "\n",
    "#             loss += criterion(logits, y).item()\n",
    "#             acc += accuracy_metric(labels, y).item()\n",
    "#             prec += precision_metric(labels, y).item()\n",
    "#             rec += recall_metric(labels, y).item()\n",
    "#             f1 += f1score_metric(labels, y).item()\n",
    "#             auroc += auroc_metric(probs, y).item()\n",
    "\n",
    "#     loss /= length\n",
    "#     acc /= length\n",
    "#     prec /= length\n",
    "#     rec /= length\n",
    "#     f1 /= length\n",
    "#     auroc /= length\n",
    "    \n",
    "#     baseline_perf['loss'] = loss\n",
    "#     baseline_perf['acc'] = acc\n",
    "#     baseline_perf['prec'] = prec\n",
    "#     baseline_perf['rec'] = rec\n",
    "#     baseline_perf['f1'] = f1\n",
    "#     baseline_perf['auroc'] = auroc\n",
    "\n",
    "# baseline_perf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
